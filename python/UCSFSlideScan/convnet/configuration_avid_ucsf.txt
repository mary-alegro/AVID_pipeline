[data paths]
path_local = /home/maryana/storage/Posdoc/AVID/AV13/

train_imgs_original = Training/dataset_imgs_train.hdf5
train_groundTruth = Training/dataset_groundTruth_train.hdf5

test_imgs_original =  Test2/dataset_imgs_test.hdf5
test_groundTruth = Test2/dataset_groundTruth_test.hdf5

path_project = /home/maryana/Projects/LargeSlideScan/python/UCSFSlideScan/convnet/
mean_image = Training/images/mean_image.npy



[experiment name]
name = AVID_Color


[data attributes]
#Dimensions of the patches extracted from the full images
patch_height = 48
patch_width = 48


[training settings]
#number of total patches:
N_subimgs = 190000
#if patches are extracted only inside the field of view:
inside_FOV = False
#Number of training epochs
N_epochs = 150
batch_size = 32
#if running with nohup
nohup = True


[testing settings]
#Choose the model to test: best==epoch with min loss, last==last epoch
best_last = best
#number of full images for the test (max 20)
full_images_to_test = 2
#How many original-groundTruth-prediction images are visualized in each image
N_group_visual = 1
#Compute average in the prediction, improve results but require more patches to be predicted
average_mode = True
#Only if average_mode==True. Stride for patch extraction, lower value require more patches to be predicted
stride_height = 5
stride_width = 5
#if running with nohup
nohup = False
